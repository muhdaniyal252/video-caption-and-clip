{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniyal/Desktop/video_cationing/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# necessory imports\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this model will be used for captioning the frames inside the video\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api key to get gemini up and running\n",
    "with open('key.json') as f:\n",
    "    content = json.load(f)\n",
    "    key = content.get('gemini_key')\n",
    "\n",
    "genai.configure(api_key=key)\n",
    "llm = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will jsonify the output from the gemini\n",
    "\n",
    "def jsonify(json_sting):\n",
    "    try:\n",
    "        # Remove non-JSON text before and after the JSON object using regex\n",
    "        json_regex = r'(\\{.*\\}|\\[.*\\])'  \n",
    "        matches = re.findall(json_regex, json_sting, re.DOTALL)\n",
    "\n",
    "        if not matches:\n",
    "            raise ValueError(\"No valid JSON object found in the response.\")\n",
    "            \n",
    "        cleaned_response = matches[0]\n",
    "\n",
    "        \n",
    "        # Remove extra whitespace characters\n",
    "        cleaned_response = re.sub(r'\\s+', ' ', cleaned_response)\n",
    "\n",
    "        \n",
    "        # Fix trailing commas in objects and arrays\n",
    "        cleaned_response = re.sub(r',\\s*([\\]}])', r'\\1', cleaned_response)\n",
    "\n",
    "        # Remove extra commas or add missing ones\n",
    "        cleaned_response = re.sub(r'{\\s*,', '{', cleaned_response)\n",
    "        cleaned_response = re.sub(r'\\[\\s*,', '[', cleaned_response)\n",
    "\n",
    "        # Fix invalid escape characters by removing unescaped backslashes\n",
    "        cleaned_response = re.sub(r'(?<!\\\\)\\\\(?![\"\\\\/bfnrtu])', '', cleaned_response)\n",
    "\n",
    "        # Fix invalid numbers (remove leading zeros)\n",
    "        cleaned_response = re.sub(r'\\b0+(\\d+)', r'\\1', cleaned_response)\n",
    "\n",
    "        # Remove any comments (JSON does not allow comments)\n",
    "        cleaned_response = re.sub(r'\\/\\/.*|\\/\\*.*\\*\\/', '', cleaned_response, flags=re.MULTILINE)\n",
    "\n",
    "        # Remove any misplaced control characters or invalid Unicode\n",
    "        cleaned_response = re.sub(r'[\\x00-\\x1F\\x7F]', '', cleaned_response)\n",
    "\n",
    "        # Fix improperly nested JSON (very basic handling)\n",
    "        cleaned_response = re.sub(r'\\{([^\\{\\}\\[\\]]+)\\{', r'{\\1,{', cleaned_response)\n",
    "        cleaned_response = re.sub(r'\\}([^\\{\\}\\[\\]]+)\\}', r'},\\1}', cleaned_response)\n",
    "\n",
    "        # Fix repeated keys in objects (keep the last occurrence)\n",
    "        def remove_repeated_keys(match):\n",
    "            obj_str = match.group(0)\n",
    "            try:\n",
    "                # Attempt to parse JSON object to find unique keys\n",
    "                temp_obj = json.loads(obj_str)\n",
    "                # Convert back to string to maintain original structure\n",
    "                return json.dumps(temp_obj)\n",
    "            except:\n",
    "                return obj_str  # If parsing fails, return original\n",
    "\n",
    "        cleaned_response = re.sub(r'\\{.*?\\}', remove_repeated_keys, cleaned_response)\n",
    "        \n",
    "        return json.loads(cleaned_response)\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSONDecodeError: {e}\")\n",
    "        return None\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the captions of all the frames\n",
    "def captionate_frames(frames):\n",
    "    inputs = processor(frames, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    captions = [processor.decode(i, skip_special_tokens=True) for i in outputs]\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt to make video captions more sensible\n",
    "def get_captions_and_time_frame(captions, fps, duration):\n",
    "    prompt = '''\n",
    "\t\ti am working on a video in which i have to caption the video according to the actions and activities performed in that video.\n",
    "\t\tcurrently i have the fps, duration of the video. additionally, i have extracted a random frame from each second and by using some model, i captioned those frames.\n",
    "\t\tso, for example, if a video is of 60 seconds, i have 60 frames and 60 captions.\n",
    "\t\ti am providing you the fps, total duration, and captions that are generated. i want you to update those captions and make them contextualize and summarize them a little bit that if FEELS LIKE THEY ARE FROM ORIGINAL VIDEO.\n",
    "\n",
    "\t\ti want you to return me in the format given below\n",
    "\t\t```\n",
    "\t\t[\n",
    "\t\t{\n",
    "\t\t\t\"start_time\": start_time1,\n",
    "\t\t\t\"end_time\": end_time1,\n",
    "\t\t\t\"caption\": caption1,\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"start_time\": start_time2,\n",
    "\t\t\t\"end_time\": end_time2,\n",
    "\t\t\t\"caption\": caption2,\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"start_time\": start_time3,\n",
    "\t\t\t\"end_time\": end_time3,\n",
    "\t\t\t\"caption\": caption4,\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"start_time\": start_time4,\n",
    "\t\t\t\"end_time\": end_time4,\n",
    "\t\t\t\"caption\": caption4,\n",
    "\t\t},\n",
    "\t\t...\n",
    "\t\t]\n",
    "\n",
    "\t\t```\n",
    "\n",
    "\t\there are the actual details and captions of video frames.\n",
    "\t\tfps: %d,\n",
    "\t\tduration: %d,\n",
    "\t\tcaptions:[%s]\n",
    "\t\t''' % (fps, duration, ','.join(captions))\n",
    "\n",
    "    response = llm.generate_content(prompt).text\n",
    "    json_obj = jsonify(response)\n",
    "    if json_obj is not None:\n",
    "            return json_obj\n",
    "    raise ValueError('There is a flaw in data recieved. please request again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt to find the the most relevent part from the video\n",
    "def get_video_segment(captions, fps, duration, scene):\n",
    "    prompt = '''\n",
    "    i am working with video in which i have to take out a segment of video depending upon the scene described. currently i have the fps, duration of the video. additionally, i have extracted a random frame from each second and by using some model, i captioned those frames.\n",
    "    so, for example, if a video is of 60 seconds, i have 60 frames and 60 captions.\n",
    "    i am providing you the fps, total duration, and captions that are generated. i want you to give me the start and end second of from the video that best describes the provided scene.\n",
    "\n",
    "    i want you to return me in the format given below\n",
    "    ```\n",
    "    {\n",
    "    \"start\": start time,\n",
    "    \"end\": end time\n",
    "    }\n",
    "    ```\n",
    "    here are the actual details and captions of video frames.\n",
    "    fps: %d\n",
    "    duration: %d seconds\n",
    "    scene: %s\n",
    "    captions: [%s]\n",
    "\n",
    "    NOTE: I DO NOT WANT ANY KIND OF EXPLAINATION, I DIRECTLY WANT THE ANSWER AND ASKED FORMAT\n",
    "    '''% (fps, duration, scene, ','.join(captions))\n",
    "    response = llm.generate_content(prompt).text\n",
    "    json_obj = jsonify(response)\n",
    "    if json_obj is not None:\n",
    "            return json_obj\n",
    "    raise ValueError('There is a flaw in data recieved. please request again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the video detials\n",
    "def get_video_data(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    duration = video.get(cv2.CAP_PROP_FRAME_COUNT) / fps\n",
    "    frames = []\n",
    "    for second in range(int(duration)):\n",
    "        # Move to the starting frame of the second\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, second * fps)\n",
    "        # Randomly select a frame within the second\n",
    "        random_frame = int(random.uniform(0, fps))\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, second * fps + random_frame)\n",
    "        ret, frame = video.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "    video.release()\n",
    "    return fps, duration, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main functin to captionate the video\n",
    "def caption_video(video_path):\n",
    "    fps, duration, frames = get_video_data(video_path)\n",
    "    captions = captionate_frames(frames)\n",
    "    captions_with_timeframes = get_captions_and_time_frame(captions, fps, duration)\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    text_clips = []\n",
    "    for item in captions_with_timeframes:\n",
    "        caption = item.get('caption')\n",
    "        start_time = item.get('start_time')\n",
    "        end_time = item.get('end_time')\n",
    "        text_clip = (TextClip(caption, method='caption', fontsize=18, color='white', bg_color='black')\n",
    "                .set_position('bottom',relative=True)\n",
    "                .set_start(start_time)\n",
    "                .set_duration(end_time - start_time))\n",
    "        text_clips.append(text_clip)\n",
    "    final_video = CompositeVideoClip([video_clip, *text_clips])\n",
    "    output_path = os.path.splitext(video_path)[0] + '_captioned.mp4'\n",
    "    final_video.write_videofile(output_path, codec='libx264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function to get the segment of described scene from the video\n",
    "def clip_video(video_path,scene):\n",
    "    fps, duration, frames = get_video_data(video_path)\n",
    "    captions = captionate_frames(frames)\n",
    "    time_frame = get_video_segment(captions,fps,duration,scene)\n",
    "    start = time_frame.get('start')\n",
    "    end = time_frame.get('end')\n",
    "    output_dir = os.path.dirname(video_path)\n",
    "    video_name, video_extension = os.path.splitext(os.path.basename(video_path))\n",
    "    output_video_path = os.path.join(output_dir, f\"{video_name}_segment{video_extension}\")\n",
    "    video = VideoFileClip(video_path)\n",
    "    video_segment = video.subclip(start, end)\n",
    "    video_segment.write_videofile(output_video_path, codec=\"libx264\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
